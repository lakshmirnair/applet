{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maml_mini-imagenet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshmirnair/applet/blob/master/maml_mini_imagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYK_yfWdrC9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1762f40-f861-4701-e915-e8e849439d28"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "!pip install learn2learn\n",
        "import learn2learn as l2l\n",
        "from learn2learn.data.transforms import (NWays,\n",
        "                                         KShots,\n",
        "                                         LoadData,\n",
        "                                         RemapLabels,\n",
        "                                         ConsecutiveLabels)\n",
        "\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)\n",
        "\n",
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        adaptation_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        adaptation_error /= len(adaptation_data)\n",
        "        learner.adapt(adaptation_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    evaluation_error = loss(predictions, evaluation_labels)\n",
        "    evaluation_error /= len(evaluation_data)\n",
        "    evaluation_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return evaluation_error, evaluation_accuracy\n",
        "\n",
        "\n",
        "def main(\n",
        "        ways=5,\n",
        "        shots=3,\n",
        "        meta_lr=0.003,\n",
        "        fast_lr=0.5,\n",
        "        meta_batch_size=32,\n",
        "        adaptation_steps=1,\n",
        "        num_iterations=60000,\n",
        "        cuda=True,\n",
        "        seed=42,\n",
        "):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    device = torch.device('cpu')\n",
        "    if cuda and torch.cuda.device_count():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        device = torch.device('cuda')\n",
        "\n",
        "    # Create Tasksets using the benchmark interface\n",
        "    tasksets = l2l.vision.benchmarks.get_tasksets('mini-imagenet',\n",
        "                                                  train_samples=2*shots,\n",
        "                                                  train_ways=ways,\n",
        "                                                  test_samples=2*shots,\n",
        "                                                  test_ways=ways,\n",
        "                                                  root='~/data',\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = l2l.vision.models.MiniImagenetCNN(ways)\n",
        "    model.to(device)\n",
        "    maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "    opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "    loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        opt.zero_grad()\n",
        "        meta_train_error = 0.0\n",
        "        meta_train_accuracy = 0.0\n",
        "        meta_valid_error = 0.0\n",
        "        meta_valid_accuracy = 0.0\n",
        "        for task in range(meta_batch_size):\n",
        "            # Compute meta-training loss\n",
        "            learner = maml.clone()\n",
        "            batch = tasksets.train.sample()\n",
        "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                               learner,\n",
        "                                                               loss,\n",
        "                                                               adaptation_steps,\n",
        "                                                               shots,\n",
        "                                                               ways,\n",
        "                                                               device)\n",
        "            evaluation_error.backward()\n",
        "            meta_train_error += evaluation_error.item()\n",
        "            meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "            # Compute meta-validation loss\n",
        "            learner = maml.clone()\n",
        "            batch = tasksets.validation.sample()\n",
        "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                               learner,\n",
        "                                                               loss,\n",
        "                                                               adaptation_steps,\n",
        "                                                               shots,\n",
        "                                                               ways,\n",
        "                                                               device)\n",
        "            meta_valid_error += evaluation_error.item()\n",
        "            meta_valid_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "        # Print some metrics\n",
        "        print('\\n')\n",
        "        print('Iteration', iteration)\n",
        "        print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "        print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "        print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "        print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "        # Average the accumulated gradients and optimize\n",
        "        for p in maml.parameters():\n",
        "            p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "        opt.step()\n",
        "\n",
        "    meta_test_error = 0.0\n",
        "    meta_test_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-testing loss\n",
        "        learner = maml.clone()\n",
        "        batch = tasksets.test.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                           learner,\n",
        "                                                           loss,\n",
        "                                                           adaptation_steps,\n",
        "                                                           shots,\n",
        "                                                           ways,\n",
        "                                                           device)\n",
        "        meta_test_error += evaluation_error.item()\n",
        "        meta_test_accuracy += evaluation_accuracy.item()\n",
        "    print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "    print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting learn2learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/9c/6ac5cf155baee6279a1fe4dcad8ed59131c7c33c5a805523609ec2d85810/learn2learn-0.1.2.tar.gz (321kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.18.5)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.17.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.5.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.6.1+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from learn2learn) (2.23.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->learn2learn) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->learn2learn) (1.12.0)\n",
            "Building wheels for collected packages: learn2learn\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.1.2-cp36-cp36m-linux_x86_64.whl size=836491 sha256=68a951818e324311b292a210fc239b99afbcc81dae059dcd21f74e864e4e5943\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/ae/e2/fe45cb0d10f64d01ed2d9ff42904d919924da021796b05a575\n",
            "Successfully built learn2learn\n",
            "Installing collected packages: learn2learn\n",
            "Successfully installed learn2learn-0.1.2\n",
            "Downloading mini-ImageNet -- train\n",
            "Downloading: /root/data/mini-imagenet-cache-train.pkl\n",
            "Downloading mini-ImageNet -- validation\n",
            "Downloading: /root/data/mini-imagenet-cache-validation.pkl\n",
            "Downloading mini-ImageNet -- test\n",
            "Downloading: /root/data/mini-imagenet-cache-test.pkl\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Iteration 0\n",
            "Meta Train Error 0.11082327854819596\n",
            "Meta Train Accuracy 0.23541667452082038\n",
            "Meta Valid Error 0.10900857369415462\n",
            "Meta Valid Accuracy 0.29166667559184134\n",
            "\n",
            "\n",
            "Iteration 1\n",
            "Meta Train Error 0.10696659074164927\n",
            "Meta Train Accuracy 0.2750000087544322\n",
            "Meta Valid Error 0.10944312950596213\n",
            "Meta Valid Accuracy 0.23333334177732468\n",
            "\n",
            "\n",
            "Iteration 2\n",
            "Meta Train Error 0.10701689939014614\n",
            "Meta Train Accuracy 0.266666674753651\n",
            "Meta Valid Error 0.11008032504469156\n",
            "Meta Valid Accuracy 0.27083334140479565\n",
            "\n",
            "\n",
            "Iteration 3\n",
            "Meta Train Error 0.10628528567031026\n",
            "Meta Train Accuracy 0.2958333413116634\n",
            "Meta Valid Error 0.1079073476139456\n",
            "Meta Valid Accuracy 0.258333342615515\n",
            "\n",
            "\n",
            "Iteration 4\n",
            "Meta Train Error 0.10433838004246354\n",
            "Meta Train Accuracy 0.29375000996515155\n",
            "Meta Valid Error 0.10663084127008915\n",
            "Meta Valid Accuracy 0.2791666758712381\n",
            "\n",
            "\n",
            "Iteration 5\n",
            "Meta Train Error 0.10512840421870351\n",
            "Meta Train Accuracy 0.27500000805594027\n",
            "Meta Valid Error 0.10445646056905389\n",
            "Meta Valid Accuracy 0.29583334061317146\n",
            "\n",
            "\n",
            "Iteration 6\n",
            "Meta Train Error 0.10442785383202136\n",
            "Meta Train Accuracy 0.3125000090803951\n",
            "Meta Valid Error 0.10644890554249287\n",
            "Meta Valid Accuracy 0.2854166757315397\n",
            "\n",
            "\n",
            "Iteration 7\n",
            "Meta Train Error 0.1041474025696516\n",
            "Meta Train Accuracy 0.268750007962808\n",
            "Meta Valid Error 0.10397816682234406\n",
            "Meta Valid Accuracy 0.2916666741948575\n",
            "\n",
            "\n",
            "Iteration 8\n",
            "Meta Train Error 0.10353530570864677\n",
            "Meta Train Accuracy 0.2875000082422048\n",
            "Meta Valid Error 0.10561243025586009\n",
            "Meta Valid Accuracy 0.2854166745673865\n",
            "\n",
            "\n",
            "Iteration 9\n",
            "Meta Train Error 0.10483537404797971\n",
            "Meta Train Accuracy 0.29791667591780424\n",
            "Meta Valid Error 0.10650370689108968\n",
            "Meta Valid Accuracy 0.262500009033829\n",
            "\n",
            "\n",
            "Iteration 10\n",
            "Meta Train Error 0.1023634176235646\n",
            "Meta Train Accuracy 0.3041666755452752\n",
            "Meta Valid Error 0.10433080233633518\n",
            "Meta Valid Accuracy 0.2958333413116634\n",
            "\n",
            "\n",
            "Iteration 11\n",
            "Meta Train Error 0.10213040956296027\n",
            "Meta Train Accuracy 0.3520833430811763\n",
            "Meta Valid Error 0.10691942553967237\n",
            "Meta Valid Accuracy 0.2854166754987091\n",
            "\n",
            "\n",
            "Iteration 12\n",
            "Meta Train Error 0.1029093055985868\n",
            "Meta Train Accuracy 0.3458333411253989\n",
            "Meta Valid Error 0.10604056343436241\n",
            "Meta Valid Accuracy 0.28125000884756446\n",
            "\n",
            "\n",
            "Iteration 13\n",
            "Meta Train Error 0.1032394366338849\n",
            "Meta Train Accuracy 0.26041667396202683\n",
            "Meta Valid Error 0.10439938376657665\n",
            "Meta Valid Accuracy 0.27500000898726285\n",
            "\n",
            "\n",
            "Iteration 14\n",
            "Meta Train Error 0.10222409479320049\n",
            "Meta Train Accuracy 0.30625000898726285\n",
            "Meta Valid Error 0.1066924452316016\n",
            "Meta Valid Accuracy 0.2625000081025064\n",
            "\n",
            "\n",
            "Iteration 15\n",
            "Meta Train Error 0.10192579589784145\n",
            "Meta Train Accuracy 0.3145833406597376\n",
            "Meta Valid Error 0.10281034628860652\n",
            "Meta Valid Accuracy 0.3020833423361182\n",
            "\n",
            "\n",
            "Iteration 16\n",
            "Meta Train Error 0.10302135394886136\n",
            "Meta Train Accuracy 0.31250000884756446\n",
            "Meta Valid Error 0.10210699564777315\n",
            "Meta Valid Accuracy 0.3104166763368994\n",
            "\n",
            "\n",
            "Iteration 17\n",
            "Meta Train Error 0.1011330233886838\n",
            "Meta Train Accuracy 0.3291666752193123\n",
            "Meta Valid Error 0.10379824973642826\n",
            "Meta Valid Accuracy 0.29791667591780424\n",
            "\n",
            "\n",
            "Iteration 18\n",
            "Meta Train Error 0.10378503752872348\n",
            "Meta Train Accuracy 0.3000000084284693\n",
            "Meta Valid Error 0.10271302051842213\n",
            "Meta Valid Accuracy 0.2895833416841924\n",
            "\n",
            "\n",
            "Iteration 19\n",
            "Meta Train Error 0.10301203443668783\n",
            "Meta Train Accuracy 0.3187500089406967\n",
            "Meta Valid Error 0.10142665053717792\n",
            "Meta Valid Accuracy 0.3104166751727462\n",
            "\n",
            "\n",
            "Iteration 20\n",
            "Meta Train Error 0.09986064815893769\n",
            "Meta Train Accuracy 0.3354166769422591\n",
            "Meta Valid Error 0.10662369756028056\n",
            "Meta Valid Accuracy 0.29166667396202683\n",
            "\n",
            "\n",
            "Iteration 21\n",
            "Meta Train Error 0.10357341449707747\n",
            "Meta Train Accuracy 0.3312500088941306\n",
            "Meta Valid Error 0.10800449387170374\n",
            "Meta Valid Accuracy 0.2520833406597376\n",
            "\n",
            "\n",
            "Iteration 22\n",
            "Meta Train Error 0.1007874880451709\n",
            "Meta Train Accuracy 0.32500000740401447\n",
            "Meta Valid Error 0.10437702923081815\n",
            "Meta Valid Accuracy 0.30833334010094404\n",
            "\n",
            "\n",
            "Iteration 23\n",
            "Meta Train Error 0.10244508367031813\n",
            "Meta Train Accuracy 0.3166666738688946\n",
            "Meta Valid Error 0.10513382498174906\n",
            "Meta Valid Accuracy 0.28125000931322575\n",
            "\n",
            "\n",
            "Iteration 24\n",
            "Meta Train Error 0.10168153746053576\n",
            "Meta Train Accuracy 0.32500000949949026\n",
            "Meta Valid Error 0.10459781112149358\n",
            "Meta Valid Accuracy 0.314583342988044\n",
            "\n",
            "\n",
            "Iteration 25\n",
            "Meta Train Error 0.10172784561291337\n",
            "Meta Train Accuracy 0.33333334256894886\n",
            "Meta Valid Error 0.10488452832214534\n",
            "Meta Valid Accuracy 0.2750000082887709\n",
            "\n",
            "\n",
            "Iteration 26\n",
            "Meta Train Error 0.09905878477729857\n",
            "Meta Train Accuracy 0.36041667591780424\n",
            "Meta Valid Error 0.1037494488991797\n",
            "Meta Valid Accuracy 0.287500009406358\n",
            "\n",
            "\n",
            "Iteration 27\n",
            "Meta Train Error 0.09943558950908482\n",
            "Meta Train Accuracy 0.35833334480412304\n",
            "Meta Valid Error 0.10627508093602955\n",
            "Meta Valid Accuracy 0.27500000852160156\n",
            "\n",
            "\n",
            "Iteration 28\n",
            "Meta Train Error 0.10160965495742857\n",
            "Meta Train Accuracy 0.32916667708195746\n",
            "Meta Valid Error 0.10308909486047924\n",
            "Meta Valid Accuracy 0.2875000082422048\n",
            "\n",
            "\n",
            "Iteration 29\n",
            "Meta Train Error 0.10243263863958418\n",
            "Meta Train Accuracy 0.32500000949949026\n",
            "Meta Valid Error 0.10453692683950067\n",
            "Meta Valid Accuracy 0.30416667414829135\n",
            "\n",
            "\n",
            "Iteration 30\n",
            "Meta Train Error 0.09964650450274348\n",
            "Meta Train Accuracy 0.36041667591780424\n",
            "Meta Valid Error 0.10529762390069664\n",
            "Meta Valid Accuracy 0.2854166750330478\n",
            "\n",
            "\n",
            "Iteration 31\n",
            "Meta Train Error 0.10353983077220619\n",
            "Meta Train Accuracy 0.32500000949949026\n",
            "Meta Valid Error 0.10366643941961229\n",
            "Meta Valid Accuracy 0.29375000740401447\n",
            "\n",
            "\n",
            "Iteration 32\n",
            "Meta Train Error 0.10161875910125673\n",
            "Meta Train Accuracy 0.32083334238268435\n",
            "Meta Valid Error 0.10732970619574189\n",
            "Meta Valid Accuracy 0.262500009033829\n",
            "\n",
            "\n",
            "Iteration 33\n",
            "Meta Train Error 0.10164658748544753\n",
            "Meta Train Accuracy 0.35625000833533704\n",
            "Meta Valid Error 0.102505455724895\n",
            "Meta Valid Accuracy 0.32083334238268435\n",
            "\n",
            "\n",
            "Iteration 34\n",
            "Meta Train Error 0.10619974159635603\n",
            "Meta Train Accuracy 0.26666667545214295\n",
            "Meta Valid Error 0.10336688882671297\n",
            "Meta Valid Accuracy 0.2958333417773247\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}